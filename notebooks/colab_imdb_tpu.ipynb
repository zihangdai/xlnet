{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab_XLNet_FineTuning",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-malte/Colab-XLNet-FineTuning/blob/master/notebooks/colab_imdb_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcBBxHAVKsna",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "**XLNet** is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Additionally, XLNet employs [Transformer-XL](https://arxiv.org/abs/1901.02860) as the backbone model, exhibiting excellent performance for language tasks involving long context. Overall, XLNet achieves state-of-the-art (SOTA) results on various downstream language tasks including question answering, natural language inference, sentiment analysis, and document ranking.\n",
        "\n",
        "For a detailed description of technical details and experimental results, please refer to our paper:\n",
        "\n",
        "​        [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237)\n",
        "\n",
        "​        Zhilin Yang\\*, Zihang Dai\\*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le \n",
        "\n",
        "​        (*: equal contribution) \n",
        "\n",
        "​        Preprint 2019\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Results\n",
        "\n",
        "As of June 19, 2019, XLNet outperforms BERT on 20 tasks and achieves state-of-the-art results on 18 tasks. Below are some comparison between XLNet-Large and BERT-Large, which have similar model sizes:\n",
        "\n",
        "### Results on Reading Comprehension\n",
        "\n",
        "Model | [RACE accuracy](http://www.qizhexie.com/data/RACE_leaderboard.html) | SQuAD1.1 EM | SQuAD2.0 EM\n",
        "--- | --- | --- | ---\n",
        "BERT | 72.0 | 84.1 | 78.98\n",
        "XLNet | **81.75** | **88.95** | **86.12**\n",
        "\n",
        "We use SQuAD dev results in the table to exclude other factors such as using additional training data or other data augmentation techniques. See [SQuAD leaderboard](https://rajpurkar.github.io/SQuAD-explorer/) for test numbers.\n",
        "\n",
        "### Results on Text Classification\n",
        "\n",
        "Model | IMDB | Yelp-2 | Yelp-5 | DBpedia | Amazon-2 | Amazon-5\n",
        "--- | --- | --- | --- | --- | --- | ---\n",
        "BERT | 4.51 | 1.89 | 29.32 | 0.64 | 2.63 | 34.17\n",
        "XLNet | **3.79** | **1.55** | **27.80** | **0.62** | **2.40** | **32.26**\n",
        "\n",
        "The above numbers are error rates.\n",
        "\n",
        "### Results on GLUE\n",
        "\n",
        "Model | MNLI | QNLI | QQP | RTE | SST-2 | MRPC | CoLA | STS-B\n",
        "--- | --- | --- | --- | --- | --- | --- | --- | ---\n",
        "BERT | 86.6 | 92.3 | 91.3 | 70.4 | 93.2 | 88.0 | 60.6 | 90.0\n",
        "XLNet | **89.8** | **93.9** | **91.8** | **83.8** | **95.6** | **89.2** | **63.6** | **91.8**\n",
        "\n",
        "We use single-task dev results in the table to exclude other factors such as multi-task learning or using ensembles.\n",
        "\n",
        "## Pre-trained models\n",
        "\n",
        "### Released Models\n",
        "\n",
        "As of <u>June 19, 2019</u>, the following model has been made available:\n",
        "* **[`XLNet-Large, Cased`](https://storage.googleapis.com/xlnet/released_models/cased_L-24_H-1024_A-16.zip)**: 24-layer, 1024-hidden, 16-heads\n",
        "\n",
        "Each .zip file contains three items:\n",
        "*   A TensorFlow checkpoint (`xlnet_model.ckpt`) containing the pre-trained weights (which is actually 3 files).\n",
        "*   A [Sentence Piece](https://github.com/google/sentencepiece) model (`spiece.model`) used for (de)tokenization.\n",
        "*   A config file (`xlnet_config.json`) which specifies the hyperparameters of the model.\n",
        "\n",
        "\n",
        "### Future Release Plan\n",
        "\n",
        "We also plan to continuously release more pretrained models under different settings, including:\n",
        "* **Base models (very soon)**: We will release an XLNet-Base by the end of June, 2019.\n",
        "* **Uncased models (soon)** : For now, cased XLNet-Large is generally better than uncased XLNet-Large. We are still investigating this observation. When a conclusion is reached, we will release the uncased models.\n",
        "* A pretrained model that is **finetuned on Wikipedia**. This can be used for tasks with Wikipedia text such as SQuAD and HotpotQA.\n",
        "* Pretrained models with other hyperparameter configurations, targeting specific downstream tasks.\n",
        "* Pretrained models that benefit from new techniques.\n",
        "\n",
        "### Subscribing to XLNet on Google Groups\n",
        "\n",
        "To receive notifications about updates, announcements and new releases, we recommend subscribing to the XLNet on [Google Groups](https://groups.google.com/forum/#!forum/xlnet).\n",
        "\n",
        "\n",
        "\n",
        "## Fine-tuning with XLNet\n",
        "\n",
        "As of <u>June 19, 2019</u>, this code base has been tested with TensorFlow 1.13.1 under Python2.\n",
        "\n",
        "### Memory Issue during Finetuning\n",
        "\n",
        "- Most of the SOTA results in our paper were produced on TPUs, which generally have more RAM than common GPUs. As a result, it is currently very difficult (costly) to re-produce most of the `XLNet-Large` SOTA results in the paper using GPUs with 12GB - 16GB of RAM, because a 16GB GPU is only able to hold a <u>single sequence with length 512</u> for `XLNet-Large`. Therefore, a large number (ranging from 32 to 128, equal to `batch_size`) of GPUs are required to reproduce many results in the paper.\n",
        "- We are experimenting with gradient accumulation to potentially relieve the memory burden, which could be included in a near-future update.\n",
        "- **Alternative methods** of finetuning XLNet on **constrained hardware** have been presented in [renatoviolin's repo](https://github.com/renatoviolin/xlnet), which obtained 86.24 F1 on SQuAD2.0 with a 8GB memory GPU.\n",
        "\n",
        "Given the memory issue mentioned above, using the default finetuning scripts (`run_classifier.py` and `run_squad.py`), we benchmarked the maximum batch size on a single **16GB** GPU with TensorFlow **1.13.1**:\n",
        "\n",
        "| System        | Seq Length | Max Batch Size |\n",
        "| ------------- | ---------- | -------------- |\n",
        "| `XLNet-Base`  | 64         | 120            |\n",
        "| ...           | 128        | 56             |\n",
        "| ...           | 256        | 24             |\n",
        "| ...           | 512        | 8              |\n",
        "| `XLNet-Large` | 64         | 16             |\n",
        "| ...           | 128        | 8              |\n",
        "| ...           | 256        | 2              |\n",
        "| ...           | 512        | 1              |\n",
        "\n",
        "In most cases, it is possible to reduce the batch size `train_batch_size` or the maximum sequence length `max_seq_length` to fit in given hardware. The decrease in performance depends on the task and the available resources.\n",
        "\n",
        "\n",
        "### Text Classification/Regression\n",
        "\n",
        "The code used to perform classification/regression finetuning is in `run_classifier.py`. It also contains examples for standard one-document classification, one-document regression, and document pair classification. Here, we provide two concrete examples of how `run_classifier.py` can be used.\n",
        "\n",
        "From here on, we assume XLNet-Large and XLNet-base has been downloaded to `$LARGE_DIR` and `$BASE_DIR` respectively.\n",
        "\n",
        "\n",
        "#### (1) STS-B: sentence pair relevance regression (with GPUs)\n",
        "\n",
        "- Download the [GLUE data](https://gluebenchmark.com/tasks) by running [this script](https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e) and unpack it to some directory `$GLUE_DIR`.\n",
        "\n",
        "- Perform **multi-GPU** (4 V100 GPUs) finetuning with XLNet-Large by running\n",
        "\n",
        "  ```shell\n",
        "  CUDA_VISIBLE_DEVICES=0,1,2,3 python run_classifier.py \\\n",
        "    --do_train=True \\\n",
        "    --do_eval=False \\\n",
        "    --task_name=sts-b \\\n",
        "    --data_dir=${GLUE_DIR}/STS-B \\\n",
        "    --output_dir=proc_data/sts-b \\\n",
        "    --model_dir=exp/sts-b \\\n",
        "    --uncased=False \\\n",
        "    --spiece_model_file=${LARGE_DIR}/spiece.model \\\n",
        "    --model_config_path=${LARGE_DIR}/xlnet_config.json \\\n",
        "    --init_checkpoint=${LARGE_DIR}/xlnet_model.ckpt \\\n",
        "    --max_seq_length=128 \\\n",
        "    --train_batch_size=8 \\\n",
        "    --num_hosts=1 \\\n",
        "    --num_core_per_host=4 \\\n",
        "    --learning_rate=5e-5 \\\n",
        "    --train_steps=1200 \\\n",
        "    --warmup_steps=120 \\\n",
        "    --save_steps=600 \\\n",
        "    --is_regression=True\n",
        "  ```\n",
        "\n",
        "- Evaluate the finetuning results with a single GPU by\n",
        "\n",
        "  ```shell\n",
        "  CUDA_VISIBLE_DEVICES=0 python run_classifier.py \\\n",
        "    --do_train=False \\\n",
        "    --do_eval=True \\\n",
        "    --task_name=sts-b \\\n",
        "    --data_dir=${GLUE_DIR}/STS-B \\\n",
        "    --output_dir=proc_data/sts-b \\\n",
        "    --model_dir=exp/sts-b \\\n",
        "    --uncased=False \\\n",
        "    --spiece_model_file=${LARGE_DIR}/spiece.model \\\n",
        "    --model_config_path=${LARGE_DIR}/xlnet_config.json \\\n",
        "    --max_seq_length=128 \\\n",
        "    --eval_batch_size=8 \\\n",
        "    --num_hosts=1 \\\n",
        "    --num_core_per_host=1 \\\n",
        "    --eval_all_ckpt=True \\\n",
        "    --is_regression=True\n",
        "\n",
        "  # Expected performance: \"eval_pearsonr 0.916+ \"\n",
        "  ```\n",
        "\n",
        "**Notes**:\n",
        "\n",
        "- In the context of GPU training, `num_core_per_host` denotes the number of GPUs to use.\n",
        "- In the multi-GPU setting, `train_batch_size` refers to the <u>per-GPU batch size</u>.\n",
        "- `eval_all_ckpt` allows one to evaluate all saved checkpoints (save frequency is controlled by `save_steps`) after training finishes and choose the best model based on dev performance.\n",
        "- `data_dir` and `output_dir` refer to the directories of the \"raw data\" and \"preprocessed tfrecords\" respectively, while `model_dir` is the working directory for saving checkpoints and tensorflow events. **`model_dir` should be set as a separate folder to `init_checkpoint`.**\n",
        "- To try out <u>XLNet-base</u>, one can simply set `--train_batch_size=32` and `--num_core_per_host=1`, along with according changes in `init_checkpoint` and `model_config_path`.\n",
        "- For GPUs with smaller RAM, please proportionally decrease the `train_batch_size` and increase `num_core_per_host` to use the same training setting.\n",
        "- **Important**: we separate the training and evaluation into \"two phases\", as using multi GPUs to perform evaluation is tricky (one has to correctly separate the data across GPUs). To ensure correctness, we only support single-GPU evaluation for now.\n",
        "\n",
        "\n",
        "#### (2) IMDB: movie review sentiment classification (with TPU V3-8)\n",
        "\n",
        "- Download and unpack the IMDB dataset by running\n",
        "\n",
        "  ```shell\n",
        "  wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "  tar zxvf aclImdb_v1.tar.gz\n",
        "  ```\n",
        "\n",
        "- Launch a Google cloud TPU V3-8 instance (see the [Google Cloud TPU tutorial](https://cloud.google.com/tpu/docs/tutorials/mnist) for how to set up Cloud TPUs).\n",
        "\n",
        "- Set up your Google storage bucket path `$GS_ROOT` and move the IMDB dataset and pretrained checkpoint into your Google storage.\n",
        "\n",
        "- Perform TPU finetuning with XLNet-Large by running\n",
        "\n",
        "  ```shell\n",
        "  python run_classifier.py \\\n",
        "    --use_tpu=True \\\n",
        "    --tpu=${TPU_NAME} \\\n",
        "    --do_train=True \\\n",
        "    --do_eval=True \\\n",
        "    --eval_all_ckpt=True \\\n",
        "    --task_name=imdb \\\n",
        "    --data_dir=${IMDB_DIR} \\\n",
        "    --output_dir=${GS_ROOT}/proc_data/imdb \\\n",
        "    --model_dir=${GS_ROOT}/exp/imdb \\\n",
        "    --uncased=False \\\n",
        "    --spiece_model_file=${LARGE_DIR}/spiece.model \\\n",
        "    --model_config_path=${GS_ROOT}/${LARGE_DIR}/model_config.json \\\n",
        "    --init_checkpoint=${GS_ROOT}/${LARGE_DIR}/xlnet_model.ckpt \\\n",
        "    --max_seq_length=512 \\\n",
        "    --train_batch_size=32 \\\n",
        "    --eval_batch_size=8 \\\n",
        "    --num_hosts=1 \\\n",
        "    --num_core_per_host=8 \\\n",
        "    --learning_rate=2e-5 \\\n",
        "    --train_steps=4000 \\\n",
        "    --warmup_steps=500 \\\n",
        "    --save_steps=500 \\\n",
        "    --iterations=500\n",
        "\n",
        "  # Expected performance: \"eval_accuracy 0.962+ \"\n",
        "  ```\n",
        "\n",
        "**Notes**:\n",
        "\n",
        "- To obtain the SOTA on the IMDB dataset, using sequence length 512 is **necessary**. Therefore, we show how this can be done with a TPU V3-8.\n",
        "- Alternatively, one can use a sequence length smaller than 512, a smaller batch size, or switch to XLNet-base to train on GPUs. But performance drop is expected.\n",
        "- Notice that the `data_dir` and `spiece_model_file` both use a local path rather than a Google Storage path. The reason is that data preprocessing is actually performed locally. Hence, using local paths leads to a faster preprocessing speed.\n",
        "\n",
        "### SQuAD2.0\n",
        "\n",
        "The code for the SQuAD dataset is included in `run_squad.py`.\n",
        "\n",
        "To run the code:\n",
        "\n",
        "(1) Download the SQuAD2.0 dataset into `$SQUAD_DIR` by:\n",
        "\n",
        "```shell\n",
        "mkdir -p ${SQUAD_DIR} && cd ${SQUAD_DIR}\n",
        "wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
        "wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
        "```\n",
        "\n",
        "(2) Perform data preprocessing using the script `scripts/prepro_squad.sh`.\n",
        "\n",
        "- This will take quite some time in order to accurately map character positions (raw data) to sentence piece positions (used for training).\n",
        "\n",
        "- For faster parallel preprocessing, please refer to the flags `--num_proc` and `--proc_id` in `run_squad.py`.\n",
        "\n",
        "(3) Perform training and evaluation.\n",
        "\n",
        "For the best performance, XLNet-Large uses <u>sequence length 512</u> and <u>batch size 48</u> for training.\n",
        "\n",
        "- As a result, reproducing the best result with GPUs is quite difficult.\n",
        "\n",
        "- For training with one TPU v3-8, one can simply run the script `scripts/tpu_squad_large.sh` after both the TPU and Google storage have been setup.\n",
        "- `run_squad.py` will automatically perform threshold searching on the dev set of squad and output the score. With `scripts/tpu_squad_large.sh`, the expected F1 score should be around 88.6 (median of our multiple runs).\n",
        "\n",
        "Alternatively, one can use XLNet-Base with GPUs (e.g. three V100). One set of reasonable hyper-parameters can be found in the script `scripts/gpu_squad_base.sh`.\n",
        "\n",
        "\n",
        "### RACE reading comprehension\n",
        "\n",
        "The code for the reading comprehension task [RACE](https://www.cs.cmu.edu/~glai1/data/race/) is included in `run_race.py`.\n",
        "\n",
        "- Notably, the average length of the passages in RACE is over 300 tokens (not peices), which is <u>significantly longer</u> than other popular reading comprehension datasets such as SQuAD.\n",
        "- Also, many questions can be very difficult and requires complex reasoning for machines to solve (see [one example here](misc/race_example.md)).\n",
        "\n",
        "\n",
        "To run the code:\n",
        "\n",
        "(1) Download the RACE dataset from the [official website](https://www.cs.cmu.edu/~glai1/data/race/) and unpack the raw data to `$RACE_DIR`.\n",
        "\n",
        "(2) Perform training and evaluation:\n",
        "\n",
        "- The SOTA performance (accuracy 81.75) of RACE is produced using XLNet-Large with sequence length 512 and batch size 32, which requires a large TPU v3-32 in the pod setting. Please refer to the script `script/tpu_race_large_bsz32.sh` for this setting.\n",
        "- Using XLNet-Large with sequence length 512 and batch size 8 on a TPU v3-8 can give you an accuracy of around 80.3 (see `script/tpu_race_large_bsz8.sh`).\n",
        "\n",
        "### Using Google Colab\n",
        "\n",
        "[An example](notebooks/colab_imdb_gpu.ipynb) of using Google Colab with GPUs has been provided. Note that since the hardware is constrained in the example, the results are worse than the best we can get. It mainly serves as an example and should be modified accordingly to maximize performance.\n",
        "\n",
        "\n",
        "## Custom Usage of XLNet\n",
        "\n",
        "### XLNet Abstraction\n",
        "\n",
        "For finetuning, it is likely that you will be able to modify existing files such as `run_classifier.py`, `run_squad.py` and `run_race.py` for your task at hand. However, we also provide an abstraction of XLNet to enable more flexible usage. Below is an example:\n",
        "\n",
        "```python\n",
        "import xlnet\n",
        "\n",
        "# some code omitted here...\n",
        "# initialize FLAGS\n",
        "# initialize instances of tf.Tensor, including input_ids, seg_ids, and input_mask\n",
        "\n",
        "# XLNetConfig contains hyperparameters that are specific to a model checkpoint.\n",
        "xlnet_config = xlnet.XLNetConfig(json_path=FLAGS.model_config_path)\n",
        "\n",
        "# RunConfig contains hyperparameters that could be different between pretraining and finetuning.\n",
        "run_config = xlnet.create_run_config(is_training=True, is_finetune=True, FLAGS=FLAGS)\n",
        "\n",
        "# Construct an XLNet model\n",
        "xlnet_model = xlnet.XLNetModel(\n",
        "    xlnet_config=xlnet_config,\n",
        "    run_config=run_config,\n",
        "    input_ids=input_ids,\n",
        "    seg_ids=seg_ids,\n",
        "    input_mask=input_mask)\n",
        "\n",
        "# Get a summary of the sequence using the last hidden state\n",
        "summary = xlnet_model.get_pooled_out(summary_type=\"last\")\n",
        "\n",
        "# Get a sequence output\n",
        "seq_out = xlnet_model.get_sequence_output()\n",
        "\n",
        "# build your applications based on `summary` or `seq_out`\n",
        "```\n",
        "\n",
        "### Tokenization\n",
        "\n",
        "Below is an example of doing tokenization in XLNet:\n",
        "```python\n",
        "import sentencepiece as spm\n",
        "from prepro_utils import preprocess_text, encode_ids\n",
        "\n",
        "# some code omitted here...\n",
        "# initialize FLAGS\n",
        "\n",
        "text = \"An input text string.\"\n",
        "\n",
        "sp_model = spm.SentencePieceProcessor()\n",
        "sp_model.Load(FLAGS.spiece_model_file)\n",
        "text = preprocess_text(text, lower=FLAGS.uncased)\n",
        "ids = encode_ids(sp_model, text)\n",
        "```\n",
        "where `FLAGS.spiece_model_file` is the SentencePiece model file in the same zip as the pretrained model, `FLAGS.uncased` is a bool indicating whether to do uncasing.\n",
        "\n",
        "\n",
        "## Pretraining with XLNet\n",
        "\n",
        "Refer to `train.py` for pretraining on TPUs and `train_gpu.py` for pretraining on GPUs. First we need to preprocess the text data into tfrecords.\n",
        "\n",
        "```shell\n",
        "python data_utils.py \\\n",
        "\t--bsz_per_host=32 \\\n",
        "\t--num_core_per_host=16 \\\n",
        "\t--seq_len=512 \\\n",
        "\t--reuse_len=256 \\\n",
        "\t--input_glob=*.txt \\\n",
        "\t--save_dir=${SAVE_DIR} \\\n",
        "\t--num_passes=20 \\\n",
        "\t--bi_data=True \\\n",
        "\t--sp_path=spiece.model \\\n",
        "\t--mask_alpha=6 \\\n",
        "\t--mask_beta=1 \\\n",
        "\t--num_predict=85\n",
        "```\n",
        "\n",
        "where `input_glob` defines all input text files, `save_dir` is the output directory for tfrecords, and `sp_path` is a [Sentence Piece](https://github.com/google/sentencepiece) model. Here is our script to train the Sentence Piece model\n",
        "\n",
        "```bash\n",
        "spm_train \\\n",
        "\t--input=$INPUT \\\n",
        "\t--model_prefix=sp10m.cased.v3 \\\n",
        "\t--vocab_size=32000 \\\n",
        "\t--character_coverage=0.99995 \\\n",
        "\t--model_type=unigram \\\n",
        "\t--control_symbols=<cls>,<sep>,<pad>,<mask>,<eod> \\\n",
        "\t--user_defined_symbols=<eop>,.,(,),\",-,–,£,€ \\\n",
        "\t--shuffle_input_sentence \\\n",
        "\t--input_sentence_size=10000000\n",
        "```\n",
        "\n",
        "Special symbols are used, including `control_symbols` and `user_defined_symbols`. We use `<eop>` and `<eod>` to denote End of Paragraph and End of Document respectively.\n",
        "\n",
        "The input text files to `data_utils.py` must use the following format:\n",
        "* Each line is a sentence.\n",
        "* An empty line means End of Document.\n",
        "* (Optional) If one also wants to model paragraph structures, `<eop>` can be inserted at the end of certain lines (without any space) to indicate that the corresponding sentence ends a paragraph.\n",
        "\n",
        "For example, the text input file could be:\n",
        "```\n",
        "This is the first sentence.\n",
        "This is the second sentence and also the end of the paragraph.<eop>\n",
        "Another paragraph.\n",
        "\n",
        "Another document starts here.\n",
        "```\n",
        "\n",
        "After preprocessing, we are ready to pretrain an XLNet. Below are the hyperparameters used for pretraining XLNet-Large:\n",
        "\n",
        "```shell\n",
        "python train.py\n",
        "  --record_info_dir=$DATA/tfrecords \\\n",
        "  --train_batch_size=2048 \\\n",
        "  --seq_len=512 \\\n",
        "  --reuse_len=256 \\\n",
        "  --mem_len=384 \\\n",
        "  --perm_size=256 \\\n",
        "  --n_layer=24 \\\n",
        "  --d_model=1024 \\\n",
        "  --d_embed=1024 \\\n",
        "  --n_head=16 \\\n",
        "  --d_head=64 \\\n",
        "  --d_inner=4096 \\\n",
        "  --untie_r=True \\\n",
        "  --mask_alpha=6 \\\n",
        "  --mask_beta=1 \\\n",
        "  --num_predict=85\n",
        "```\n",
        "\n",
        "where we only list the most important flags and the other flags could be adjusted based on specific use cases.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v4pPpSjME_M",
        "colab_type": "text"
      },
      "source": [
        "#Colab TPU Demo on IMDB Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nogla7ILAr8A",
        "colab_type": "text"
      },
      "source": [
        "## Install sentencepiece\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyg_OpLWAKhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTLUKj4SJ86r",
        "colab_type": "text"
      },
      "source": [
        "##Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXG1d-yWHcPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#install dependencies\n",
        "import os\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import pandas as pd  \n",
        "import subprocess\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdMmwCJFaT8F",
        "colab_type": "text"
      },
      "source": [
        "## Set up the TPU and connect to Cloud Bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "191zq3ZErihP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "print(os.environ)\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xTjVroYDdm4",
        "colab_type": "text"
      },
      "source": [
        "##Download GitHub Repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxguVChxp2fI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "git_url = \"https://github.com/aditya-malte/Colab-XLNet-FineTuning.git\"  #@param {type:\"string\"}\n",
        "os.system(\"git clone \"+git_url)\n",
        "%cd Colab-XLNet-FineTuning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgpISXC_Ax_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git pull origin master\n",
        "#Use if you have updated git repo and want changes to reflect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAeHkJ_8AbNi",
        "colab_type": "text"
      },
      "source": [
        "##Download the IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHQH4OCHZ9bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar zxvf aclImdb_v1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW8k3tDRTndN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "repo_name = 'Colab-XLNet-FineTuning' #@param {type:\"string\"}\n",
        "%ls\n",
        "%cd {repo_name}\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkTLZ3I4_7c_",
        "colab_type": "text"
      },
      "source": [
        "# XLNet End to End (Fine-tuning + Evaluation) in 5 minutes with Cloud TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld-JXlueIuPH",
        "colab_type": "text"
      },
      "source": [
        "## Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POkof5uHaQ_c",
        "colab_type": "text"
      },
      "source": [
        "<h3><a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>  &nbsp;&nbsp;Train on TPU</h3>\n",
        "\n",
        "   1. Create a Cloud Storage bucket for your TensorBoard logs at http://console.cloud.google.com/storage and fill in the BUCKET parameter in the \"Parameters\" section below.\n",
        " \n",
        "   1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "   1. Click Runtime again and select **Runtime > Run All** (Watch out: the \"Colab-only auth for this notebook and the TPU\" cell requires user input). You can also run the cells manually with Shift-ENTER."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYkaAlJNfhul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TASK = 'IMDB' #@param {type:\"string\"}\n",
        "\n",
        "TASK_DATA_DIR = 'aclImdb' #@param {type:\"string\"}\n",
        "print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n",
        "!ls $TASK_DATA_DIR\n",
        "\n",
        "BUCKET = 'YOUR_BUCKET_NAME' #@param {type:\"string\"}\n",
        "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
        "OUTPUT_DIR = 'gs://{}/xlnet/output/{}'.format(BUCKET, TASK)\n",
        "MODEL_DIR = 'gs://{}/xlnet/model/{}'.format(BUCKET, TASK)\n",
        "\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "tf.gfile.MakeDirs(MODEL_DIR)\n",
        "\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYXW_2vsKGPi",
        "colab_type": "text"
      },
      "source": [
        "##Download the XLNet-Large model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7eW79mM8Qdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.system(\"wget https://storage.googleapis.com/xlnet/released_models/cased_L-24_H-1024_A-16.zip\")\n",
        "os.system(\"unzip cased_L-24_H-1024_A-16.zip\")\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpofnyuR_sYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd xlnet_cased_L-24_H-1024_A-16\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6STFA7rYyStw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_names = os.listdir(os.getcwd())\n",
        "print(file_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOBt0E9IQTS-",
        "colab_type": "text"
      },
      "source": [
        "##Copy the weights to Google Cloud Bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtzjAQT6wZbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file_name in file_names:\n",
        "  print(file_name)\n",
        "  os.system(\"gsutil cp \"+ file_name + \" \" + MODEL_DIR)\n",
        "os.system(\"gsutil ls \" + MODEL_DIR)\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEVts1yAKQ6E",
        "colab_type": "text"
      },
      "source": [
        "##Copy the spiece.model file to local directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn6ljng_B-EF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.system(\"gsutil cp -r \" + MODEL_DIR + \"/spiece.model spiece.model\")\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaxC5jzNKZHT",
        "colab_type": "text"
      },
      "source": [
        "##Choose Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vinj3p_X96ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BATCH_SIZE = 32\n",
        "EVAL_BATCH_SIZE = 8\n",
        "PREDICT_BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-5\n",
        "MAX_SEQ_LENGTH = 256\n",
        "NUM_TRAIN_STEPS = 4000\n",
        "WARMUP_STEPS = 500\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 500\n",
        "NUM_ITERATIONS = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMJxfmBaKb7H",
        "colab_type": "text"
      },
      "source": [
        "##Run Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kyacr8InG8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_command = \"python run_classifier.py \\\n",
        "  --use_tpu=True \\\n",
        "  --use_colab_tpu=True \\\n",
        "  --do_train=True \\\n",
        "  --do_eval=False \\\n",
        "  --task_name=\"+TASK.lower()+\" \\\n",
        "  --data_dir=./\"+TASK_DATA_DIR+\" \\\n",
        "  --output_dir=\"+OUTPUT_DIR+\" \\\n",
        "  --model_dir=\"+MODEL_DIR+\" \\\n",
        "  --uncased=False \\\n",
        "  --tpu_address=\"+TPU_ADDRESS+\"  \\\n",
        "  --spiece_model_file=./spiece.model \\\n",
        "  --model_config_path=\"+MODEL_DIR+\"/xlnet_config.json \\\n",
        "  --init_checkpoint=\"+MODEL_DIR+\"/xlnet_model.ckpt \\\n",
        "  --max_seq_length=\"+str(MAX_SEQ_LENGTH)+\" \\\n",
        "  --train_batch_size=\"+str(TRAIN_BATCH_SIZE)+\" \\\n",
        "  --eval_batch_size=\"+str(EVAL_BATCH_SIZE)+\" \\\n",
        "  --num_hosts=1 \\\n",
        "  --num_core_per_host=8 \\\n",
        "  --learning_rate=\"+str(LEARNING_RATE)+\" \\\n",
        "  --train_steps=\"+str(NUM_TRAIN_STEPS)+\" \\\n",
        "  --warmup_steps=\"+str(WARMUP_STEPS)+\" \\\n",
        "  --save_steps=\"+str(SAVE_CHECKPOINTS_STEPS)+\" \\\n",
        "  --iterations=\"+ str(NUM_ITERATIONS)\n",
        "\n",
        "print(train_command)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX2y2tQcMJ3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!{train_command}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z7zetx0Kfrj",
        "colab_type": "text"
      },
      "source": [
        "##Run Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk8fzA3J4e5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_command = \"python run_classifier.py \\\n",
        "  --use_tpu=True \\\n",
        "  --use_colab_tpu=True \\\n",
        "  --do_train=False \\\n",
        "  --do_eval=True \\\n",
        "  --eval_all_ckpt=True \\\n",
        "  --task_name=\"+TASK.lower()+\" \\\n",
        "  --data_dir=./\"+TASK_DATA_DIR+\" \\\n",
        "  --output_dir=\"+OUTPUT_DIR+\" \\\n",
        "  --model_dir=\"+OUTPUT_DIR+\" \\\n",
        "  --uncased=False \\\n",
        "  --tpu_address=\"+TPU_ADDRESS+\"  \\\n",
        "  --spiece_model_file=./spiece.model \\\n",
        "  --model_config_path=\"+MODEL_DIR+\"/xlnet_config.json \\\n",
        "  --init_checkpoint=\"+MODEL_DIR+\"/xlnet_model.ckpt \\\n",
        "  --max_seq_length=\"+str(MAX_SEQ_LENGTH)+\" \\\n",
        "  --train_batch_size=\"+str(TRAIN_BATCH_SIZE)+\" \\\n",
        "  --eval_batch_size=\"+str(EVAL_BATCH_SIZE)+\" \\\n",
        "  --num_hosts=1 \\\n",
        "  --num_core_per_host=8 \\\n",
        "  --learning_rate=2e-5 \\\n",
        "  --train_steps=\"+str(NUM_TRAIN_STEPS)+\" \\\n",
        "  --warmup_steps=\"+str(WARMUP_STEPS)+\" \\\n",
        "  --save_steps=\"+str(SAVE_CHECKPOINTS_STEPS)+\" \\\n",
        "  --iterations=\"+ str(NUM_ITERATIONS)\n",
        "\n",
        "print(eval_command)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmrsBPq34wOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!{eval_command}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}